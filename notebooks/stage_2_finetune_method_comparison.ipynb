{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2dab65-4132-4824-9ab9-28404275e237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gluonts.dataset.pandas import PandasDataset, is_uniform, infer_freq\n",
    "from gluonts.dataset.split import split, TestData\n",
    "from uni2ts.model.moirai import MoiraiForecast, MoiraiModule\n",
    "from uni2ts.eval_util.plot import plot_single, plot_next_multi\n",
    "from uni2ts.eval_util.evaluation import evaluate_model\n",
    "from gluonts.ev.metrics import MAE, MAPE\n",
    "\n",
    "from mov_av import moving_average\n",
    "from uni2ts.alex.common.benchmark_func import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39bbaf8-8241-4e8c-aca2-5ffba59da0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "it_data_23_24 = pd.read_csv(\"data/it_load_data_23_24.csv\", delimiter=\",\")\n",
    "it_data_23_24[\"DateUTC\"] = pd.to_datetime(it_data_23_24[\"DateUTC\"])\n",
    "it_data_23_24 = it_data_23_24.set_index(\"DateUTC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f5a213-2834-4e64-b07a-c62a3305f2b4",
   "metadata": {},
   "source": [
    "## Stage 2 Finetuning method comparison\n",
    "\n",
    "For the second round of finetuning, there are 3 different ways that it can happen:\n",
    "\n",
    "- Having the model from Stage 1 we start the training using this model. After the 1st training iteration ends we save the modified model and use it on the next iteration and so on ... In training iteration N we use the trained model from iteraion N-1. (refit_t_thorough_f)\n",
    "- At every training iteration we use as a starting model the Stage 1 model, which we further finetune with the all the available data up to that point. (refit_f_thorough_f)\n",
    "\n",
    "In both of the afrementioned methods we only perform 1 backward pass of the available data.\n",
    "\n",
    "- At every training iteration we use as a starting model the Stage 1 model, which we further finetune with the all the available data up to that point for more than 1 epochs (slightly different training configuration). (refit_f_thorough_t)\n",
    "\n",
    "For example, in the pictre below our case is shown. The difference between the first method and the other two is the model with which we start each training iteration. In the first we use a different one each time, but in the other two we use the same model and only data change.\n",
    "\n",
    "![](https://miro.medium.com/v2/resize:fit:1400/0*E0xyoKfV9p5nOhTF.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d71597-2af9-4114-b1a7-74d5a8d91007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_v2(model_folder: str, data: pd.DataFrame):\n",
    "    metrics = {\"mean\": [], \"median\": [], \"lower_0025\": [], \"upper_0975\": []}\n",
    "    for i in range(1, 52):\n",
    "        try:\n",
    "            model, test_data = get_model_data(\n",
    "                model_folder=model_folder,\n",
    "                prediction_lenght=168,\n",
    "                num_of_weeks=i,\n",
    "                data=data,\n",
    "                patch_size=\"auto\",\n",
    "                num_samples=500,\n",
    "            )\n",
    "\n",
    "            forecast_samples, target_values = get_eval_foreasts(model, test_data)\n",
    "\n",
    "            # absolute error of the average forecast of each time step\n",
    "            mean_error_ts = (\n",
    "                np.mean(forecast_samples, axis=1).flatten() - target_values.flatten()\n",
    "            ) / target_values.flatten()\n",
    "            mean_error_ts = np.abs(mean_error_ts)\n",
    "\n",
    "            # absolute error of the median forecast of each time step\n",
    "            median_error_ts = (\n",
    "                np.quantile(forecast_samples, 0.5, axis=1).flatten()\n",
    "                - target_values.flatten()\n",
    "            ) / target_values.flatten()\n",
    "            median_error_ts = np.abs(median_error_ts)\n",
    "\n",
    "            # absolute error of the 97.5th percentile forecast of each time step\n",
    "            upper_error_ts = (\n",
    "                np.quantile(forecast_samples, 0.975, axis=1).flatten()\n",
    "                - target_values.flatten()\n",
    "            ) / target_values.flatten()\n",
    "            upper_error_ts = np.abs(upper_error_ts)\n",
    "\n",
    "            # absolute error of the 2.5th percentile forecast of each time step\n",
    "            lower_error_ts = (\n",
    "                np.quantile(forecast_samples, 0.025, axis=1).flatten()\n",
    "                - target_values.flatten()\n",
    "            ) / target_values.flatten()\n",
    "            lower_error_ts = np.abs(lower_error_ts)\n",
    "\n",
    "            metrics[\"mean\"].append(mean_error_ts)\n",
    "            metrics[\"median\"].append(median_error_ts)\n",
    "            metrics[\"lower_0025\"].append(lower_error_ts)\n",
    "            metrics[\"upper_0975\"].append(upper_error_ts)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40662ff-acc4-495f-a821-5fe8e1896d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = it_data_23_24\n",
    "\n",
    "model_folder = (\n",
    "    \"outputs/finetune/moirai_small/refit_t_thorough_f/checkpoints/it_load_data_train_\"\n",
    ")\n",
    "backtesting_with_refit = get_metrics_v2(model_folder, data)\n",
    "\n",
    "model_folder = (\n",
    "    \"outputs/finetune/moirai_small/refit_f_thorough_f/checkpoints/it_load_data_train_\"\n",
    ")\n",
    "refit_1_pass = get_metrics_v2(model_folder, data)\n",
    "\n",
    "model_folder = (\n",
    "    \"outputs/finetune/moirai_small/refit_f_thorough_t/checkpoints/it_load_data_train_\"\n",
    ")\n",
    "refit_multiple_passes = get_metrics_v2(model_folder, data)\n",
    "\n",
    "model_folder = \"outputs/finetune/moirai_small/refit_f_thorough_t_dropout_01/checkpoints/it_load_data_train_\"\n",
    "refit_multiple_passes_v2 = get_metrics_v2(model_folder, data)\n",
    "\n",
    "model_folder = \"pretrained\"\n",
    "pretrained = get_metrics_v2(model_folder, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22efa5aa-cfd3-4535-b62e-f3963bd1f864",
   "metadata": {},
   "outputs": [],
   "source": [
    "backtesting_with_refit = pd.DataFrame.from_dict(backtesting_with_refit)\n",
    "refit_1_pass = pd.DataFrame.from_dict(refit_1_pass)\n",
    "refit_multiple_passes = pd.DataFrame.from_dict(refit_multiple_passes)\n",
    "refit_multiple_passes_v2 = pd.DataFrame.from_dict(refit_multiple_passes_v2)\n",
    "pretrained = pd.DataFrame.from_dict(pretrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752e92df-951b-41a8-bf25-fae9aee628ba",
   "metadata": {},
   "source": [
    "As far as the 3rd method is concerned, mutliple backward passes, one would think why not try different dropout levels as well to determine a little more optimized approach. The plot below examines exactly that and it seems that dropout doesn't improve performance in our situation. So in the later comparisons we only include the method without dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9323c67b-f827-45a7-923b-67b653d60398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAPE of the average forecast\n",
    "plt.title(\"Thorough training method comparison\")\n",
    "plt.ylabel(\"MAPE of the mean forecast\")\n",
    "plt.xlabel(\"Weeks of available data\")\n",
    "plt.errorbar(\n",
    "    x=range(1, 52),\n",
    "    y=[np.mean(ts) for ts in refit_multiple_passes[\"mean\"].tolist()],\n",
    "    ecolor=\"red\",\n",
    "    barsabove=True,\n",
    "    linestyle=\"dotted\",\n",
    "    marker=\".\",\n",
    "    errorevery=2,\n",
    "    label=\"Dropout: 0%\",\n",
    ")\n",
    "plt.errorbar(\n",
    "    x=range(1, 43),\n",
    "    y=[np.mean(ts) for ts in refit_multiple_passes_v2[\"mean\"].tolist()],\n",
    "    ecolor=\"red\",\n",
    "    barsabove=True,\n",
    "    linestyle=\"dotted\",\n",
    "    marker=\".\",\n",
    "    errorevery=2,\n",
    "    label=\"Dropout: 10%\",\n",
    ")\n",
    "plt.legend()\n",
    "plt.savefig(\n",
    "    \"experiment_results/stage_2_finetune_method_comp/thorough_training_method_comparison.jpeg\"\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef42db35-4fc5-4521-aa7a-16cdea675fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAPE of the average forecast\n",
    "plt.title(\"Stage 2 Finetuning method comparison\")\n",
    "plt.ylabel(\"MAPE of the mean forecast\")\n",
    "plt.xlabel(\"Weeks of available data\")\n",
    "plt.errorbar(\n",
    "    x=range(1, 52),\n",
    "    y=[np.mean(ts) for ts in backtesting_with_refit[\"mean\"].tolist()],\n",
    "    ecolor=\"red\",\n",
    "    barsabove=True,\n",
    "    linestyle=\"dotted\",\n",
    "    marker=\".\",\n",
    "    errorevery=2,\n",
    "    label=\"refit_t_thorough_f\",\n",
    ")\n",
    "plt.errorbar(\n",
    "    x=range(1, 52),\n",
    "    y=[np.mean(ts) for ts in refit_1_pass[\"mean\"].tolist()],\n",
    "    ecolor=\"red\",\n",
    "    barsabove=True,\n",
    "    linestyle=\"dotted\",\n",
    "    marker=\".\",\n",
    "    errorevery=2,\n",
    "    label=\"refit_f_thorough_f\",\n",
    ")\n",
    "plt.errorbar(\n",
    "    x=range(1, 52),\n",
    "    y=[np.mean(ts) for ts in refit_multiple_passes[\"mean\"].tolist()],\n",
    "    ecolor=\"red\",\n",
    "    barsabove=True,\n",
    "    linestyle=\"dotted\",\n",
    "    marker=\".\",\n",
    "    errorevery=2,\n",
    "    label=\"refit_f_thorough_t\",\n",
    ")\n",
    "plt.legend()\n",
    "plt.savefig(\n",
    "    \"experiment_results/stage_2_finetune_method_comp/stage_2_finetune_method_comp_mean.jpeg\"\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f222dbb-88ea-4414-b6bf-8ad57da7b48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAPE of the 97.5th percentile forecast\n",
    "plt.title(\"Stage 2 Finetuning method comparison\")\n",
    "plt.ylabel(\"MAPE of the 97.5th percentile forecast\")\n",
    "plt.xlabel(\"Weeks of available data\")\n",
    "plt.errorbar(\n",
    "    x=range(1, 52),\n",
    "    y=[np.mean(ts) for ts in backtesting_with_refit[\"upper_0975\"].tolist()],\n",
    "    ecolor=\"red\",\n",
    "    barsabove=True,\n",
    "    linestyle=\"dotted\",\n",
    "    marker=\".\",\n",
    "    errorevery=2,\n",
    "    label=\"refit_t_thorough_f\",\n",
    ")\n",
    "plt.errorbar(\n",
    "    x=range(1, 52),\n",
    "    y=[np.mean(ts) for ts in refit_1_pass[\"upper_0975\"].tolist()],\n",
    "    ecolor=\"red\",\n",
    "    barsabove=True,\n",
    "    linestyle=\"dotted\",\n",
    "    marker=\".\",\n",
    "    errorevery=2,\n",
    "    label=\"refit_f_thorough_f\",\n",
    ")\n",
    "plt.errorbar(\n",
    "    x=range(1, 52),\n",
    "    y=[np.mean(ts) for ts in refit_multiple_passes[\"upper_0975\"].tolist()],\n",
    "    ecolor=\"red\",\n",
    "    barsabove=True,\n",
    "    linestyle=\"dotted\",\n",
    "    marker=\".\",\n",
    "    errorevery=2,\n",
    "    label=\"refit_f_thorough_t\",\n",
    ")\n",
    "plt.legend()\n",
    "plt.savefig(\n",
    "    \"experiment_results/stage_2_finetune_method_comp/stage_2_finetune_method_comp_975.jpeg\"\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33505d9-5baa-4485-b367-af36d23a2041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAPE of the 2.5th percentile forecast\n",
    "plt.title(\"Stage 2 Finetuning method comparison\")\n",
    "plt.ylabel(\"MAPE of the 2.5th forecast\")\n",
    "plt.xlabel(\"Weeks of available data\")\n",
    "plt.errorbar(\n",
    "    x=range(1, 52),\n",
    "    y=[np.mean(ts) for ts in backtesting_with_refit[\"lower_0025\"].tolist()],\n",
    "    ecolor=\"red\",\n",
    "    barsabove=True,\n",
    "    linestyle=\"dotted\",\n",
    "    marker=\".\",\n",
    "    errorevery=2,\n",
    "    label=\"refit_t_thorough_f\",\n",
    ")\n",
    "plt.errorbar(\n",
    "    x=range(1, 52),\n",
    "    y=[np.mean(ts) for ts in refit_1_pass[\"lower_0025\"].tolist()],\n",
    "    ecolor=\"red\",\n",
    "    barsabove=True,\n",
    "    linestyle=\"dotted\",\n",
    "    marker=\".\",\n",
    "    errorevery=2,\n",
    "    label=\"refit_f_thorough_f\",\n",
    ")\n",
    "plt.errorbar(\n",
    "    x=range(1, 52),\n",
    "    y=[np.mean(ts) for ts in refit_multiple_passes[\"lower_0025\"].tolist()],\n",
    "    ecolor=\"red\",\n",
    "    barsabove=True,\n",
    "    linestyle=\"dotted\",\n",
    "    marker=\".\",\n",
    "    errorevery=2,\n",
    "    label=\"refit_f_thorough_t\",\n",
    ")\n",
    "plt.legend()\n",
    "plt.savefig(\n",
    "    \"experiment_results/stage_2_finetune_method_comp/stage_2_finetune_method_comp_025.jpeg\"\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66324ea5-b308-4630-aef6-cb11e5e00a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAPE of the median forecast\n",
    "plt.title(\"Stage 2 Finetuning method comparison\")\n",
    "plt.ylabel(\"MAPE of the median forecast\")\n",
    "plt.xlabel(\"Weeks of available data\")\n",
    "plt.errorbar(\n",
    "    x=range(1, 52),\n",
    "    y=[np.mean(ts) for ts in backtesting_with_refit[\"median\"].tolist()],\n",
    "    ecolor=\"red\",\n",
    "    barsabove=True,\n",
    "    linestyle=\"dotted\",\n",
    "    marker=\".\",\n",
    "    errorevery=2,\n",
    "    label=\"refit_t_thorough_f\",\n",
    ")\n",
    "plt.errorbar(\n",
    "    x=range(1, 52),\n",
    "    y=[np.mean(ts) for ts in refit_1_pass[\"median\"].tolist()],\n",
    "    ecolor=\"red\",\n",
    "    barsabove=True,\n",
    "    linestyle=\"dotted\",\n",
    "    marker=\".\",\n",
    "    errorevery=2,\n",
    "    label=\"refit_f_thorough_f\",\n",
    ")\n",
    "plt.errorbar(\n",
    "    x=range(1, 52),\n",
    "    y=[np.mean(ts) for ts in refit_multiple_passes[\"median\"].tolist()],\n",
    "    ecolor=\"red\",\n",
    "    barsabove=True,\n",
    "    linestyle=\"dotted\",\n",
    "    marker=\".\",\n",
    "    errorevery=2,\n",
    "    label=\"refit_f_thorough_t\",\n",
    ")\n",
    "plt.legend()\n",
    "plt.savefig(\n",
    "    \"experiment_results/stage_2_finetune_method_comp/stage_2_finetune_method_comp_median.jpeg\"\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d97a7e-4101-4d6f-b4a3-3ba8f2758b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
